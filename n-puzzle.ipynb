{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions â€” see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem description with live demo: [`https://tristanpenman.com/demos/n-puzzle/`](https://tristanpenman.com/demos/n-puzzle/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from typing import Any, Deque\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import artist\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase recursion limit for DFS and IDS\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "# Default initial and goal states\n",
    "DEFAULT_INITIAL_STATE: NDArray = np.array(\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [0, 7, 8],\n",
    "    ]\n",
    ")\n",
    "\n",
    "DEFAULT_GOAL_STATE: NDArray = np.array(\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(state: NDArray[np.int32]) -> NDArray[np.int32]:\n",
    "    neighbors: list[NDArray[np.int32]] = []\n",
    "    x, y = np.argwhere(state == 0)[0]\n",
    "    moves: list[tuple[int, int]] = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Up, Down, Left, Right\n",
    "    for dx, dy in moves:\n",
    "        nx, ny = x + dx, y + dy\n",
    "        if 0 <= nx < state.shape[0] and 0 <= ny < state.shape[1]:\n",
    "            new_state: NDArray[np.int32] = state.copy()\n",
    "            new_state[x, y], new_state[nx, ny] = new_state[nx, ny], new_state[x, y]\n",
    "            neighbors.append(new_state)\n",
    "    return np.array(neighbors)\n",
    "\n",
    "\n",
    "def search_util(\n",
    "    current_state: NDArray[np.int32],\n",
    "    goal_state: NDArray[np.int32],\n",
    "    visited: set[bytes],\n",
    "    path: list[NDArray[np.int32]],\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "):\n",
    "    if depth > max_depth:\n",
    "        return None\n",
    "    if np.array_equal(current_state, goal_state):\n",
    "        return path + [current_state]\n",
    "    visited.add(current_state.tobytes())\n",
    "    for neighbor in get_neighbors(current_state):\n",
    "        if neighbor not in visited:\n",
    "            result = search_util(neighbor, goal_state, visited, path + [current_state], depth + 1, max_depth)\n",
    "            if result is not None:\n",
    "                return result\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth-First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        initial_state: NDArray[np.int32] = DEFAULT_INITIAL_STATE,\n",
    "        goal_state: NDArray[np.int32] = DEFAULT_GOAL_STATE,\n",
    "    ) -> None:\n",
    "        self.initial_state: NDArray[np.int32] = initial_state\n",
    "        self.goal_state: NDArray[np.int32] = goal_state\n",
    "        # The initial state is the first visited state\n",
    "        self.visited: list[NDArray[np.int32]] = [initial_state]\n",
    "        self.queue: Deque[tuple[NDArray, list]] = deque()\n",
    "\n",
    "    def solve(self) -> list | None:\n",
    "        self.queue.append((self.initial_state, []))\n",
    "\n",
    "        while self.queue:\n",
    "            current_state, path = self.queue.popleft()\n",
    "            if np.array_equal(current_state, self.goal_state):\n",
    "                print(f\"BFS: Number of steps = {len(path)}\")\n",
    "                return path + [current_state]\n",
    "            for neighbor in get_neighbors(current_state):\n",
    "                # If the neighbor has not been visited before\n",
    "                if not np.any([np.array_equal(neighbor, history) for history in self.visited]):\n",
    "                    self.visited.append(neighbor)\n",
    "                    self.queue.append((neighbor, path + [current_state]))\n",
    "        print(\"BFS: No solution found\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFS:\n",
    "    def __init__(self, initial_state=DEFAULT_INITIAL_STATE, goal_state=DEFAULT_GOAL_STATE) -> None:\n",
    "        self.initial_state = initial_state\n",
    "        self.goal_state = goal_state\n",
    "        self.visited = set()\n",
    "        self.path = []\n",
    "        self.depth = 0\n",
    "        self.max_depth = sys.getrecursionlimit()\n",
    "\n",
    "    def solve(self):\n",
    "        self.path = search_util(self.initial_state, self.goal_state, self.visited, [], self.depth, self.max_depth)\n",
    "        if self.path is not None:\n",
    "            print(f\"DFS: Number of steps = {len(self.path) - 1}\")\n",
    "            return self.path\n",
    "        else:\n",
    "            print(\"DFS: No solution found\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Deepening Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDS:\n",
    "    def __init__(self, initial_state=DEFAULT_INITIAL_STATE, goal_state=DEFAULT_GOAL_STATE):\n",
    "        self.initial_state = initial_state\n",
    "        self.goal_state = goal_state\n",
    "        self.visited = set()\n",
    "        self.path = []\n",
    "        self.max_depth = 0\n",
    "\n",
    "    def solve(self):\n",
    "        while True:\n",
    "            self.visited = set()\n",
    "            self.path = search_util(self.initial_state, self.goal_state, self.visited, [], 0, self.max_depth)\n",
    "            if self.path is not None:\n",
    "                print(f\"IDS: Number of steps = {len(self.path) - 1}\")\n",
    "                return self.path\n",
    "            self.max_depth += 1\n",
    "        print(\"IDS: No solution found\")\n",
    "        print(\"Anyway: How did you get here?\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Collection, Sequence\n",
    "from matplotlib.artist import Artist\n",
    "from matplotlib.image import AxesImage\n",
    "\n",
    "\n",
    "def save_solution_video(path: list[NDArray[np.int32]]) -> None:\n",
    "    frames: Sequence[Collection[Artist]] = []\n",
    "    N: int = path[0].shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(N, N))\n",
    "    ax.axis('off')\n",
    "    texts = [[ax.text(j, i, '', va='center', ha='center', fontsize=16, color='white') for j in range(N)] for i in range(N)]\n",
    "    for state in path:\n",
    "        img: AxesImage = ax.imshow(np.zeros((N, N)), cmap='gray', vmin=0, vmax=N * N - 1)\n",
    "        for (i, j), val in np.ndenumerate(state):\n",
    "            texts[i][j].set_text(str(val) if val != 0 else '')\n",
    "        frames.append([img] + [text for row in texts for text in row])\n",
    "\n",
    "    def get_frame(i):\n",
    "        return frames[i]\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, get_frame, frames=len(frames), interval=2000, blit=True, repeat=True)\n",
    "    # plt.show(fig)\n",
    "    # To save the animation using Pillow as a gif\n",
    "    writer = animation.PillowWriter(fps=1, bitrate=1800)\n",
    "    ani.save('solution.gif', writer=writer)\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_solution_video2(path: list[np.ndarray]) -> None:\n",
    "    frames: Sequence[Collection[Artist]] = []\n",
    "    N: int = path[0].shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(N, N))\n",
    "    ax.axis('off')\n",
    "    texts = [[ax.text(j, i, '', va='center', ha='center', fontsize=16, color='white') for j in range(N)] for i in range(N)]\n",
    "    for state in path:\n",
    "        img: AxesImage = ax.imshow(np.zeros((N, N)), cmap='gray', vmin=0, vmax=N * N - 1)\n",
    "        for (i, j), val in np.ndenumerate(state):\n",
    "            texts[i][j].set_text(str(val) if val != 0 else '')\n",
    "        frames.append([img] + [text for row in texts for text in row])\n",
    "\n",
    "    print(f\"Total frames generated: {len(frames)}\")\n",
    "\n",
    "    def get_frame(i):\n",
    "        return frames[i]\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, get_frame, frames=len(frames), interval=2000, blit=True, repeat=True)\n",
    "    plt.show(fig)  # Uncomment this line to display the animation\n",
    "    # To save the animation using Pillow as a gif\n",
    "    writer = animation.PillowWriter(fps=1, bitrate=1800)\n",
    "    ani.save('solution.gif', writer=writer)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS: Number of steps = 2\n",
      "Total frames generated: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_state = DEFAULT_INITIAL_STATE\n",
    "goal_state = DEFAULT_GOAL_STATE\n",
    "\n",
    "# Solve using Breadth First Search\n",
    "bfs_path = BFS(initial_state, goal_state).solve()\n",
    "if bfs_path:\n",
    "    save_solution_video2(bfs_path)\n",
    "\n",
    "# # Solve using Deep First Search\n",
    "# dfs_path = DFS(initial_state, goal_state).solve()\n",
    "# if dfs_path:\n",
    "#     visualize_solution(dfs_path)\n",
    "\n",
    "# # Solve using Iterative Deepening Search\n",
    "# ids_path = IDS(initial_state, goal_state).solve()\n",
    "# if ids_path:\n",
    "#     visualize_solution(ids_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
